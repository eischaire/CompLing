{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала напишем правила для каждого предложения по отдельности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = 'Вася читает мою книгу'\n",
    "rules1 = \"\"\"\n",
    "S -> DP VP\n",
    "DP -> NProp\n",
    "VP -> V DP\n",
    "DP -> D NP\n",
    "NP -> APRO NP\n",
    "NP -> AP N | N\n",
    "V -> 'читает'\n",
    "NProp -> 'вася'\n",
    "N -> 'книгу'\n",
    "D -> \n",
    "APRO -> 'мою' \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence2 = 'Напиши какое-нибудь письмо'\n",
    "rules2 = \"\"\"\n",
    "S -> DP VP\n",
    "DP -> \n",
    "VP -> V DP\n",
    "DP -> D NP\n",
    "NP -> AP N\n",
    "AP -> \n",
    "V -> 'напиши'\n",
    "D -> 'какое-нибудь'\n",
    "N -> 'письмо'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence3 = 'Этот веселый мальчик идет'\n",
    "rules3 = \"\"\"\n",
    "S -> DP VP\n",
    "VP -> V\n",
    "DP -> D NP\n",
    "NP -> AP N\n",
    "AP -> A\n",
    "A -> 'веселый'\n",
    "N -> 'мальчик'\n",
    "V -> 'идет'\n",
    "D -> 'этот'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence4 = 'Он любит читать всякие книги'\n",
    "rules4 = \"\"\"\n",
    "S -> DP VP\n",
    "DP -> SPRO\n",
    "VP -> V VP\n",
    "VP -> V DP\n",
    "DP -> D NP\n",
    "NP -> AP N\n",
    "AP -> \n",
    "V -> 'любит' | 'читать'\n",
    "D -> 'всякие'\n",
    "N -> 'книги'\n",
    "SPRO -> 'он'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь соберём их вместе:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "S -> DP VP\n",
      "DP -> NProp\n",
      "VP -> V DP\n",
      "DP -> D NP\n",
      "NP -> APRO NP\n",
      "NP -> AP N | N\n",
      "V -> 'читает'\n",
      "NProp -> 'вася'\n",
      "N -> 'книгу'\n",
      "D -> \n",
      "APRO -> 'мою' \n",
      "DP -> \n",
      "NP -> AP N\n",
      "AP -> \n",
      "V -> 'напиши'\n",
      "D -> 'какое-нибудь'\n",
      "N -> 'письмо'\n",
      "VP -> V\n",
      "AP -> A\n",
      "A -> 'веселый'\n",
      "N -> 'мальчик'\n",
      "V -> 'идет'\n",
      "D -> 'этот'\n",
      "DP -> SPRO\n",
      "VP -> V VP\n",
      "V -> 'любит' | 'читать'\n",
      "D -> 'всякие'\n",
      "N -> 'книги'\n",
      "SPRO -> 'он'\n"
     ]
    }
   ],
   "source": [
    "common_rules = []\n",
    "for indiv in [rules1, rules2, rules3, rules4]:\n",
    "    for rule in indiv.split('\\n'):\n",
    "        if rule not in common_rules:\n",
    "            common_rules.append(rule)\n",
    "print('\\n'.join(common_rules))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = nltk.CFG.fromstring('\\n'.join(common_rules))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar with 31 productions (start state = S)\n",
      "    S -> DP VP\n",
      "    DP -> NProp\n",
      "    VP -> V DP\n",
      "    DP -> D NP\n",
      "    NP -> APRO NP\n",
      "    NP -> AP N\n",
      "    NP -> N\n",
      "    V -> 'читает'\n",
      "    NProp -> 'вася'\n",
      "    N -> 'книгу'\n",
      "    D -> \n",
      "    APRO -> 'мою'\n",
      "    DP -> \n",
      "    NP -> AP N\n",
      "    AP -> \n",
      "    V -> 'напиши'\n",
      "    D -> 'какое-нибудь'\n",
      "    N -> 'письмо'\n",
      "    VP -> V\n",
      "    AP -> A\n",
      "    A -> 'веселый'\n",
      "    N -> 'мальчик'\n",
      "    V -> 'идет'\n",
      "    D -> 'этот'\n",
      "    DP -> SPRO\n",
      "    VP -> V VP\n",
      "    V -> 'любит'\n",
      "    V -> 'читать'\n",
      "    D -> 'всякие'\n",
      "    N -> 'книги'\n",
      "    SPRO -> 'он'\n"
     ]
    }
   ],
   "source": [
    "print(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = nltk.EarleyChartParser(grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "проверим, что оно рисует"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tree in parser.parse('Напиши всякие книги'.lower().split()):\n",
    "    tree.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим возможность включать новые слова в разборы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_list = str(grammar).split('\\n')[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_rules_list = []\n",
    "for item in rules_list:\n",
    "    good_rules_list.append(item.strip(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S -> DP VP',\n",
       " 'DP -> NProp',\n",
       " 'VP -> V DP',\n",
       " 'DP -> D NP',\n",
       " 'NP -> APRO NP',\n",
       " 'NP -> AP N',\n",
       " \"V -> 'читает'\",\n",
       " \"NProp -> 'вася'\",\n",
       " \"N -> 'книгу'\",\n",
       " 'AP ->',\n",
       " 'D ->',\n",
       " \"APRO -> 'мою'\",\n",
       " 'DP ->',\n",
       " \"V -> 'напиши'\",\n",
       " \"D -> 'какое-нибудь'\",\n",
       " \"N -> 'письмо'\",\n",
       " 'VP -> V',\n",
       " 'AP -> A',\n",
       " \"A -> 'веселый'\",\n",
       " \"N -> 'мальчик'\",\n",
       " \"V -> 'идет'\",\n",
       " \"D -> 'этот'\",\n",
       " 'DP -> SPRO',\n",
       " 'VP -> V VP',\n",
       " \"V -> 'любит'\",\n",
       " \"V -> 'читать'\",\n",
       " \"D -> 'всякие'\",\n",
       " \"N -> 'книги'\",\n",
       " \"SPRO -> 'он'\"]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_rules_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VERB'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(morph.parse('читает')[0].tag).split(',')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_terminal(list_of_rules):\n",
    "    new_rules = []\n",
    "    for rule in list_of_rules:\n",
    "        if re.search(\"'(.+?)'\", rule):\n",
    "            rule = rule.split(' -> ')\n",
    "            pos = str(morph.parse(rule[1].strip(\"'\"))[0].tag).split(',')[0]\n",
    "            rule1 = ' -> '.join([rule[0], pos])\n",
    "            rule2 = ' -> '.join([pos, rule[1]])\n",
    "            new_rules.append(rule1)\n",
    "            new_rules.append(rule2)\n",
    "        else:\n",
    "            new_rules.append(rule)\n",
    "    return new_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "widened_rules = '\\n'.join(is_terminal(good_rules_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"S -> DP VP\\nDP -> NProp\\nVP -> V DP\\nDP -> D NP\\nNP -> APRO NP\\nNP -> AP N\\nV -> VERB\\nVERB -> 'читает'\\nNProp -> NOUN\\nNOUN -> 'вася'\\nN -> NOUN\\nNOUN -> 'книгу'\\nAP ->\\nD ->\\nAPRO -> ADJF\\nADJF -> 'мою'\\nDP ->\\nV -> VERB\\nVERB -> 'напиши'\\nD -> ADJF\\nADJF -> 'какое-нибудь'\\nN -> NOUN\\nNOUN -> 'письмо'\\nVP -> V\\nAP -> A\\nA -> ADJF\\nADJF -> 'веселый'\\nN -> NOUN\\nNOUN -> 'мальчик'\\nV -> VERB\\nVERB -> 'идет'\\nD -> ADJF\\nADJF -> 'этот'\\nDP -> SPRO\\nVP -> V VP\\nV -> VERB\\nVERB -> 'любит'\\nV -> INFN\\nINFN -> 'читать'\\nD -> ADJF\\nADJF -> 'всякие'\\nN -> NOUN\\nNOUN -> 'книги'\\nSPRO -> NPRO\\nNPRO -> 'он'\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "widened_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_grammar = nltk.CFG.fromstring(widened_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parser2 = nltk.EarleyChartParser(new_grammar)\n",
    "#for tree in parser2.parse('Напиши всякие журналы'.lower().split()):\n",
    "#    tree.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_in_grammar(sentence):\n",
    "    new_words = []\n",
    "    global widened_rules\n",
    "    for word in sentence.lower().split():\n",
    "        if not re.search(\"'{}'\".format(word), widened_rules):\n",
    "            new_words.append(' -> '.join([str(morph.parse(word)[0].tag).split(',')[0], \"'{}'\".format(word)]))\n",
    "        if new_words:\n",
    "            widened_rules = widened_rules + '\\n' + '\\n'.join(new_words)\n",
    "    new_grammar = nltk.CFG.fromstring(widened_rules)\n",
    "    parser = nltk.EarleyChartParser(new_grammar)\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_a_tree(sentence):\n",
    "    parser2 = is_in_grammar(sentence)\n",
    "    for tree in parser2.parse(sentence.lower().split()):\n",
    "        tree.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_a_tree('Умный Вася поет какие-то странные песни')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По-хорошему, можно оставить в основных правилах только переходы нетерминалов-групп в части речи, а уже их прописывать каждый раз свои в draw_a_tree (???)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortened_rules = []\n",
    "for rule in widened_rules.split('\\n'):\n",
    "    if not re.search(\"'(.+?)'\", rule):\n",
    "        shortened_rules.append(rule)\n",
    "shortened_rules = '\\n'.join(shortened_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_terms_to_grammar(sentence):\n",
    "    new_words = []\n",
    "    for word in sentence.lower().split():\n",
    "        if not re.search(\"'{}'\".format(word), shortened_rules):\n",
    "            new_words.append(' -> '.join([str(morph.parse(word)[0].tag).split(',')[0], \"'{}'\".format(word)]))\n",
    "    if new_words:\n",
    "        rules = shortened_rules + '\\n' + '\\n'.join(new_words)\n",
    "    new_grammar = nltk.CFG.fromstring(rules)\n",
    "    parser = nltk.EarleyChartParser(new_grammar)\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_all_new_words(sentence):\n",
    "    parser2 = add_terms_to_grammar(sentence)\n",
    "    for tree in parser2.parse(sentence.lower().split()):\n",
    "        print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (DP (NProp (NOUN кот)))\n",
      "  (VP\n",
      "    (V (VERB ест))\n",
      "    (DP\n",
      "      (D (ADJF всяких))\n",
      "      (NP (AP (A (ADJF плохих))) (N (NOUN мышей))))))\n",
      "(S\n",
      "  (DP (NProp (NOUN кот)))\n",
      "  (VP\n",
      "    (V (VERB ест))\n",
      "    (DP\n",
      "      (D )\n",
      "      (NP\n",
      "        (APRO (ADJF всяких))\n",
      "        (NP (AP (A (ADJF плохих))) (N (NOUN мышей)))))))\n",
      "(S\n",
      "  (DP (NProp (NOUN кот)))\n",
      "  (VP\n",
      "    (V (VERB ест))\n",
      "    (DP\n",
      "      (D )\n",
      "      (NP\n",
      "        (APRO (ADJF всяких))\n",
      "        (NP (APRO (ADJF плохих)) (NP (AP ) (N (NOUN мышей))))))))\n",
      "(S\n",
      "  (DP (NProp (NOUN кот)))\n",
      "  (VP\n",
      "    (V (VERB ест))\n",
      "    (DP\n",
      "      (D (ADJF всяких))\n",
      "      (NP (APRO (ADJF плохих)) (NP (AP ) (N (NOUN мышей)))))))\n",
      "(S\n",
      "  (DP (D ) (NP (AP ) (N (NOUN кот))))\n",
      "  (VP\n",
      "    (V (VERB ест))\n",
      "    (DP\n",
      "      (D (ADJF всяких))\n",
      "      (NP (AP (A (ADJF плохих))) (N (NOUN мышей))))))\n",
      "(S\n",
      "  (DP (D ) (NP (AP ) (N (NOUN кот))))\n",
      "  (VP\n",
      "    (V (VERB ест))\n",
      "    (DP\n",
      "      (D )\n",
      "      (NP\n",
      "        (APRO (ADJF всяких))\n",
      "        (NP (AP (A (ADJF плохих))) (N (NOUN мышей)))))))\n",
      "(S\n",
      "  (DP (D ) (NP (AP ) (N (NOUN кот))))\n",
      "  (VP\n",
      "    (V (VERB ест))\n",
      "    (DP\n",
      "      (D )\n",
      "      (NP\n",
      "        (APRO (ADJF всяких))\n",
      "        (NP (APRO (ADJF плохих)) (NP (AP ) (N (NOUN мышей))))))))\n",
      "(S\n",
      "  (DP (D ) (NP (AP ) (N (NOUN кот))))\n",
      "  (VP\n",
      "    (V (VERB ест))\n",
      "    (DP\n",
      "      (D (ADJF всяких))\n",
      "      (NP (APRO (ADJF плохих)) (NP (AP ) (N (NOUN мышей)))))))\n"
     ]
    }
   ],
   "source": [
    "tree_all_new_words('Кот ест всяких плохих мышей')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (DP (NProp (NOUN мальчик)))\n",
      "  (VP (V (VERB пишет)) (DP (NProp (NOUN рассказы)))))\n",
      "(S\n",
      "  (DP (NProp (NOUN мальчик)))\n",
      "  (VP (V (VERB пишет)) (DP (D ) (NP (AP ) (N (NOUN рассказы))))))\n",
      "(S\n",
      "  (DP (D ) (NP (AP ) (N (NOUN мальчик))))\n",
      "  (VP (V (VERB пишет)) (DP (NProp (NOUN рассказы)))))\n",
      "(S\n",
      "  (DP (D ) (NP (AP ) (N (NOUN мальчик))))\n",
      "  (VP (V (VERB пишет)) (DP (D ) (NP (AP ) (N (NOUN рассказы))))))\n"
     ]
    }
   ],
   "source": [
    "tree_all_new_words('мальчик пишет рассказы')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4-8 деревьев выглядят страшно, поэтому постараемся минимизировать переходы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S -> DP VP\n",
      "DP -> NProp\n",
      "VP -> V DP\n",
      "DP -> D NP\n",
      "NP -> APRO NP\n",
      "NP -> AP N\n",
      "V -> VERB\n",
      "NProp -> NOUN\n",
      "N -> NOUN\n",
      "AP ->\n",
      "D ->\n",
      "APRO -> ADJF\n",
      "DP ->\n",
      "V -> VERB\n",
      "D -> ADJF\n",
      "N -> NOUN\n",
      "VP -> V\n",
      "AP -> A\n",
      "A -> ADJF\n",
      "N -> NOUN\n",
      "V -> VERB\n",
      "D -> ADJF\n",
      "DP -> SPRO\n",
      "VP -> V VP\n",
      "V -> VERB\n",
      "V -> INFN\n",
      "D -> ADJF\n",
      "N -> NOUN\n",
      "SPRO -> NPRO\n"
     ]
    }
   ],
   "source": [
    "print(shortened_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'S ': [' DP VP'],\n",
       " 'DP ': [' NProp', ' D NP', '', ' SPRO'],\n",
       " 'VP ': [' V DP', ' V', ' V VP'],\n",
       " 'NP ': [' APRO NP', ' AP N'],\n",
       " 'V ': [' VERB', ' VERB', ' VERB', ' VERB', ' INFN'],\n",
       " 'NProp ': [' NOUN'],\n",
       " 'N ': [' NOUN', ' NOUN', ' NOUN', ' NOUN'],\n",
       " 'AP ': ['', ' A'],\n",
       " 'D ': ['', ' ADJF', ' ADJF', ' ADJF'],\n",
       " 'APRO ': [' ADJF'],\n",
       " 'A ': [' ADJF'],\n",
       " 'SPRO ': [' NPRO']}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "how_many_rules = {}\n",
    "for rule in shortened_rules.split('\\n'):\n",
    "    rule = rule.split('->')\n",
    "    if rule[0] not in how_many_rules:\n",
    "        how_many_rules[rule[0]] = [rule[1]]\n",
    "    else:\n",
    "        how_many_rules[rule[0]].append(rule[1])\n",
    "how_many_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь я хочу вручную переписать правила (благо их здесь немного)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonterminal_grammar = \"\"\"\n",
    "S -> DP VP\n",
    "DP -> D NP | NPRO |  \n",
    "D -> Apro | \n",
    "NP -> AP NP | NOUN\n",
    "AP -> ADJF\n",
    "VP -> V DP | V VP | V\n",
    "V -> VERB | INFN\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переопределим функцию, которая добавляет терминалы в грамматику:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_terminal(word):\n",
    "    tags = str(morph.parse(word)[0].tag).split(',')[:2]\n",
    "    if tags[1].startswith('Apro'):\n",
    "        tags = 'Apro'\n",
    "    else:\n",
    "        tags = tags[0]\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_terms_to_grammar(sentence, rules):\n",
    "    new_words = []\n",
    "    for word in sentence.lower().split():\n",
    "        new_words.append(' -> '.join([get_terminal(word), \"'{}'\".format(word)]))\n",
    "    rules = rules + '\\n' + '\\n'.join(new_words)\n",
    "    new_grammar = nltk.CFG.fromstring(rules)\n",
    "    parser = nltk.EarleyChartParser(new_grammar)\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И функцию, которая строит деревья:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_all_new_words(sentence):\n",
    "    parser = add_terms_to_grammar(sentence, nonterminal_grammar)\n",
    "    print('Producted %d tree(s)'%len(list(parser.parse(sentence.lower().split()))))\n",
    "    next(parser.parse(sentence.lower().split())).draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Producted 1 tree(s)\n"
     ]
    }
   ],
   "source": [
    "tree_all_new_words('Умный Вася поет какие-то странные песни')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Producted 1 tree(s)\n"
     ]
    }
   ],
   "source": [
    "tree_all_new_words('Кошка подавилась этой несчастной грушей')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Producted 1 tree(s)\n"
     ]
    }
   ],
   "source": [
    "tree_all_new_words('Вася поет песни')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я считаю, что это победа!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
